---
title: "incomePred"
---

# Load Libraries

```{r load_libraries}
library(bayesrules)
library(rstanarm)
library(tidyverse)
library(bayesplot)
```

# Reading in Data

```{r}
all_data <- read.csv("adult.data")
colnames(all_data) <- c("age", "workclass", "final_weight","education", "education_num", "martial-status", "occupation", "relationship", "race", "sex", "capital-gain", "capital-loss", "hours-per-week", "native-country", "income")
```

# Project Objective

Given information about an individual adult in the U.S. and we want to use Bayesian logistic regression to classify whether or not they earn more 50k or not. Specifically, we will look at the number of years of education, sex, race, and age.

# Exploratory Data Analysis

```{r clean}
adult_income <- all_data[, c("education_num", "sex", "race", "age", "income")]

adult_income$sex <- trimws(adult_income$sex)
adult_income$sex <- ifelse(adult_income$sex == "Male", 1, 0)

adult_income$income <- trimws(adult_income$income)
adult_income$income <- ifelse(adult_income$income == ">50K", 1, 0)

adult_income$race <- trimws(adult_income$race)
adult_income$race <- ifelse(adult_income$race == "White", 0,
                     ifelse(adult_income$race == "Black", 1,
                     ifelse(adult_income$race == "Asian-Pac-Islander", 2,
                     ifelse(adult_income$race == "Amer-Indian-Eskimo", 3, 4))))

colSums(is.na(adult_income))  # Count missing values in each column
sum(is.na(adult_income))  # Total missing values in dataset
```

```{r exploratory}

table(adult_income$race)  # Frequency count of Race
table(adult_income$sex)  # Frequency count of Sex 
table(adult_income$income)  # Frequency count of Income 

barplot(table(adult_income$race), main="Bar Chart of Race", col="lightblue", names.arg = c("White", "Black", "Asian", "Eskimo", "Other"), xlab = "Race", ylab = "Frequency")

barplot(table(adult_income$sex), main="Bar Chart of Sex", col="lightblue", names.arg = c("Female", "Male"), xlab = "Sex", ylab = "Frequency")

barplot(table(adult_income$income), main="Bar Chart of Income", col="lightblue", names.arg = c("<=50K", ">50K"), xlab = "Income", ylab = "Frequency")


hist(adult_income$age, main="Histogram of Age", col="lightblue", breaks=25, xlab = "Age", ylab = "Frequency")
boxplot(adult_income$age, main="Boxplot of Age", col="lightblue", horizontal = TRUE, xlab = "Age")

hist(adult_income$education_num, main="Histogram of Years of Education", col="lightblue", breaks=5, xlab = "Years of Education", ylab = "Frequency")
boxplot(adult_income$education_num, main="Boxplot of Years of Education", col="lightblue", horizontal = TRUE, xlab = "Years of Education")
```

```{r test}
test <- all_data[, c("education_num", "sex", "race", "age", "income")]

set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(adult_income), size = 0.8 * nrow(adult_income))

train_data <- adult_income[train_indices, ]
test_data <- adult_income[-train_indices, ]

bayesian_model <- stan_glm(
  income ~ education_num + factor(sex) + factor(race) + age,
  data = train_data,
  family = binomial,
  prior = normal(c(0.1, 0.5, -0.5, -0.5, -0.5, -0.5, 0.02), c(0.1, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1)),
  prior_aux = exponential(1),
  chains = 4,
  iter = 5000*2,
  seed = 84735
)

```

So for our logistic regression, the prior should reflect reasonable assumptions about the relationship between predictors and the log-odds (or odds ratio) of the outcome. For years of education, education_num, the coefficient should represent the expected change in logs-odd for every 1-unit (1 year) increase in education. We assumed a prior of 0.10 would be reasonable. It implies there's an approximate 9% increase in odds per unit increase (1 year of additional education), indicating there's a strong association between the years of education and whether or not they make more than 50K. For sex, since its a categorical and binary variable, it would either be 0 or 1. This would mean that the our coefficient for sex would be the difference in log-odds from going 0 (female) to 1 (male) while keeping all other factors constant. Given that this data set was taken from 1994, we would assume that the pay gap between males and females existed more prominently. We assumed a prior of 0.5 would be reasonable. It implies there's an approximate 33% increase in odds going from female to male, indicating there's also a strong association between sex and whether or not they make more than 50K. For race, there's a total of 4 different coefficients, each representing the difference in log-odds from the baseline (white). For the coefficient of each race, we assumed that there will be a decrease in the log-odds for every race when comparing to the baseline. In particular, we did -0.5 all. As for age, we believe there's that income tends to increase with age but at a diminishing rate. So, We assume a small positive effect of 0.02 or 2% increase in log-odds per increase in age. As for the standard deviation of the priors, we chose 0.1 for ones that we were less confident in so there's room for flexibility. For example, the number of years of education, A PhD versus a high school diploma has a huge difference, but extra years of education might not always translate to higher earnings. So allow for more variation in `education_num`. However for age, since age effects on income are well-documented and we expect a consistent but small positive relationship, we chose 0.01 to reflect our confidence. We did the same for race and sex. Since we were confident in the sex one, we left less room for variation, hence why we chose 0.1. For race, since we weren't sure if the change was the same for each race, we left more room for variation, hence the 0.1.

```{r prior_summary}
prior_summary(bayesian_model)
summary(bayesian_model)
mcmc_trace(bayesian_model, size = 0.1)
mcmc_dens_overlay(bayesian_model)
```